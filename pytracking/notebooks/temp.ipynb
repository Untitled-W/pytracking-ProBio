{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTubeVOS/2019/probio_train loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YouTubeVOS: 100%|██████████| 63/63 [00:38<00:00,  1.63seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTubeVOS/2019/probio_valid loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 63)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams['figure.figsize'] = [14, 8]\n",
    "import motmetrics as mm\n",
    "from motmetrics.distances import iou_matrix\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../..')\n",
    "from pytracking.utils.load_text import load_text\n",
    "from pytracking.evaluation import Tracker, get_dataset, trackerlist\n",
    "from pprint import pprint\n",
    "\n",
    "# trackers = [Tracker('atom','default')]\n",
    "trackers = [Tracker('tomp','tomp50')]\n",
    "# dataset = get_dataset('got10k_val')\n",
    "# dataset = get_dataset('yt2019_sub')\n",
    "# dataset = get_dataset('got10k_probio')\n",
    "# dataset = get_dataset('got10k_probio_valid')\n",
    "d1 = get_dataset('yt_pb_train')\n",
    "d2 = get_dataset('yt_pb_valid')\n",
    "\n",
    "def motMetricsEnhancedCalculator(gt, t):\n",
    "  # import required packages\n",
    "  \n",
    "  acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "  # Max frame number maybe different for gt and t files\n",
    "  for frame in range(int(gt[:,0].max())):\n",
    "    frame += 1 # detection and frame numbers begin at 1\n",
    "\n",
    "    # select id, x, y, width, height for current frame\n",
    "    # required format for distance calculation is X, Y, Width, Height \\\n",
    "    # We already have this format\n",
    "    gt_dets = gt[gt[:,0]==frame,1:6] # select all detections in gt\n",
    "    t_dets = t[t[:,0]==frame,1:6] # select all detections in t\n",
    "\n",
    "    C = mm.distances.iou_matrix(gt_dets[:,1:], t_dets[:,1:], \\\n",
    "                                max_iou=0.5) # format: gt, t\n",
    "\n",
    "    # Call update once for per frame.\n",
    "    # format: gt object ids, t object ids, distance\n",
    "    acc.update(gt_dets[:,0].astype('int').tolist(), \\\n",
    "              t_dets[:,0].astype('int').tolist(), C)\n",
    "    \n",
    "  return acc\n",
    "\n",
    "def one_track(trk):\n",
    "    names = []\n",
    "    accs = []\n",
    "\n",
    "    for seq_id, seq in enumerate(dataset):\n",
    "        base_results_path = '{}/{}'.format(trk.results_dir, seq.name)\n",
    "        gt = []\n",
    "        pred = []\n",
    "        for (obj_id, obj_gt) in list(seq.ground_truth_rect.items()):\n",
    "            results_path = '{}_{}.txt'.format(base_results_path,obj_id)\n",
    "            if os.path.isfile(results_path):\n",
    "                pred_bb = torch.tensor(load_text(str(results_path), delimiter=('\\t', ','), dtype=np.float64))\n",
    "                obj_gt = torch.tensor(obj_gt,dtype=torch.float64)\n",
    "            else:\n",
    "                print('Result not found. {}'.format(results_path))\n",
    "                continue\n",
    "            for frame_id, b in enumerate(obj_gt):\n",
    "                if b[0] == -1: continue\n",
    "                gt.append([frame_id+1,obj_id,b[0],b[1],b[2],b[3],1.,-1.,-1.,-1.])\n",
    "            for frame_id, b in enumerate(pred_bb):\n",
    "                if b[0] == -1: continue\n",
    "                pred.append([frame_id+1,obj_id,b[0],b[1],b[2],b[3],1.,-1.,-1.,-1.])\n",
    "        # if seq.name in ['0043f083b5','0044fa5fba']:\n",
    "        #     slices = slice(2,6)\n",
    "        #     print(f'----------------{seq.name}-------------')\n",
    "        #     cur_id = 0\n",
    "        #     for i,j in zip(gt,pred):\n",
    "        #         if i[1] != cur_id:\n",
    "        #             print(f'----------------{i[1]}-------------')\n",
    "        #             cur_id = i[1]\n",
    "        #         a = [f'{int(ii)-int(jj):>3}' for ii,jj in zip(i[slices],j[slices])]\n",
    "        #         bi = [int(ii) for ii in i[slices]]\n",
    "        #         bj = [int(jj) for jj in j[slices]]\n",
    "        #         c = iou_matrix([i[slices]],[j[slices]])[0][0]\n",
    "        #         print(f'{c:>5.3f}',a,bi,bj)\n",
    "        if len(gt) == 0: continue\n",
    "        accs.append(motMetricsEnhancedCalculator(np.array(gt, dtype=np.float64), np.array(pred, dtype=np.float64)))\n",
    "        names.append(seq.name)\n",
    "\n",
    "\n",
    "    mh = mm.metrics.create()\n",
    "    summary = mh.compute_many(accs, metrics=['mota', 'motp', 'num_frames', 'num_objects' , 'idf1', 'idp', 'idr', \\\n",
    "                                        'recall', 'precision',  \\\n",
    "                                        'mostly_tracked', 'partially_tracked', \\\n",
    "                                        'mostly_lost', 'num_false_positives', \\\n",
    "                                        'num_misses', 'num_switches', \\\n",
    "                                        'num_fragmentations'\n",
    "                                    ], \\\n",
    "                        generate_overall=True,\n",
    "                        names=names)\n",
    "\n",
    "    # strsummary = mm.io.render_summary(\n",
    "    #     summary,\n",
    "    #     #formatters={'mota' : '{:.2%}'.format},\n",
    "    #     namemap={'num_objects': 'GT', 'mota': 'MOTA', 'motp' : 'MOTP', \\\n",
    "    #              'idf1': 'IDF1', 'idp': 'IDP', 'idr': 'IDR', 'recall': 'Rcll', \\\n",
    "    #             'precision': 'Prcn',  \\\n",
    "    #             'mostly_tracked' : 'MT', 'partially_tracked': 'PT', \\\n",
    "    #             'mostly_lost' : 'ML', 'num_false_positives': 'FP', \\\n",
    "    #             'num_misses': 'FN', 'num_switches' : 'IDsw', \\\n",
    "    #             'num_fragmentations' : 'FM'\n",
    "    #             }\n",
    "    # )\n",
    "\n",
    "    df =  pd.DataFrame.from_dict(summary)\n",
    "    namemap = {'num_objects': 'GT', 'mota': 'MOTA', 'motp' : 'MOTP', \\\n",
    "                 'idf1': 'IDF1', 'idp': 'IDP', 'idr': 'IDR', 'recall': 'Rcll', 'precision': 'Prcn',  \\\n",
    "                'mostly_tracked' : 'MT', 'partially_tracked': 'PT', \\\n",
    "                'mostly_lost' : 'ML', 'num_false_positives': 'FP', \\\n",
    "                'num_misses': 'FN', 'num_switches' : 'IDsw', \\\n",
    "                'num_fragmentations' : 'FM', 'num_frames': 'Frames'\n",
    "                }\n",
    "    df.rename(columns=namemap, inplace=True)\n",
    "    return df\n",
    "\n",
    "def one_track_single(trk):\n",
    "    names = []\n",
    "    accs = []\n",
    "    \n",
    "    for seq_id, seq in enumerate(dataset):\n",
    "        results_path = '{}/{}.txt'.format(trk.results_dir, seq.name)\n",
    "        obj_gt = seq.ground_truth_rect\n",
    "        gt = []\n",
    "        pred = []\n",
    "        \n",
    "        def compare():\n",
    "            slices = slice(2,6)\n",
    "            print(f'----------------{seq.name}-------------')\n",
    "            cur_id = 0\n",
    "            for i,j in zip(gt,pred):\n",
    "                if i[1] != cur_id:\n",
    "                    print(f'----------------{i[1]}-------------')\n",
    "                    cur_id = i[1]\n",
    "                a = [f'{int(ii)-int(jj):>3}' for ii,jj in zip(i[slices],j[slices])]\n",
    "                bi = [int(ii) for ii in i[slices]]\n",
    "                bj = [int(jj) for jj in j[slices]]\n",
    "                c = iou_matrix([i[slices]],[j[slices]])[0][0]\n",
    "                print(f'Frame {i[0]}:',f'{c:>5.3f}',a,bi,bj)\n",
    "         \n",
    "        if os.path.isfile(results_path):\n",
    "            pred_bb = torch.tensor(load_text(str(results_path), delimiter=('\\t', ','), dtype=np.float64))\n",
    "        else:\n",
    "            # print('Result not found. {}'.format(results_path))\n",
    "            continue\n",
    "        for frame_id, b in enumerate(obj_gt):\n",
    "            if b[0] == -1: continue\n",
    "            gt.append([frame_id+1,1,b[0],b[1],b[2],b[3],1.,-1.,-1.,-1.])\n",
    "        for frame_id, b in enumerate(pred_bb):\n",
    "            if b[0] == -1: continue\n",
    "            pred.append([frame_id+1,1,b[0],b[1],b[2],b[3],1.,-1.,-1.,-1.])\n",
    "            \n",
    "        if seq.name in ['GOT-10k_Val_000007','GOT-10k_Val_000016','GOT-10k_Val_000021']: compare()\n",
    "            \n",
    "        if len(gt) == 0: continue\n",
    "        accs.append(motMetricsEnhancedCalculator(np.array(gt, dtype=np.float64), np.array(pred, dtype=np.float64)))\n",
    "        names.append(seq.name)\n",
    "        \n",
    "    mh = mm.metrics.create()\n",
    "    summary = mh.compute_many(accs, metrics=['mota', 'motp', 'num_frames', 'num_objects' , 'idf1', 'idp', 'idr', \\\n",
    "                                        'recall', 'precision',  \\\n",
    "                                        'mostly_tracked', 'partially_tracked', \\\n",
    "                                        'mostly_lost', 'num_false_positives', \\\n",
    "                                        'num_misses', 'num_switches', \\\n",
    "                                        'num_fragmentations'\n",
    "                                    ], \\\n",
    "                        generate_overall=True,\n",
    "                        names=names)\n",
    "    df =  pd.DataFrame.from_dict(summary)\n",
    "    namemap = {'num_objects': 'GT', 'mota': 'MOTA', 'motp' : 'MOTP', \\\n",
    "                 'idf1': 'IDF1', 'idp': 'IDP', 'idr': 'IDR', 'recall': 'Rcll', 'precision': 'Prcn',  \\\n",
    "                'mostly_tracked' : 'MT', 'partially_tracked': 'PT', \\\n",
    "                'mostly_lost' : 'ML', 'num_false_positives': 'FP', \\\n",
    "                'num_misses': 'FN', 'num_switches' : 'IDsw', \\\n",
    "                'num_fragmentations' : 'FM', 'num_frames': 'Frames'\n",
    "                }\n",
    "    df.rename(columns=namemap, inplace=True)\n",
    "    return df\n",
    "\n",
    "# one_track_single(trackers[0])\n",
    "len(d1),len(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/mnt/data/qizhezhang/pytracking/ltr/train_settings'\n",
    "# ltr1 = '/mnt/data/qizhezhang/pytracking/ltr/ckpt/checkpoints/ltr'\n",
    "# ltr2 = '/mnt/data/qizhezhang/pytracking/ltr/ckpt/tensorboard/ltr'\n",
    "# for model in os.listdir(path):\n",
    "#     if model == '__init__.py' or model == '__pycache__': continue\n",
    "#     for param in os.listdir(os.path.join(path,model)):\n",
    "#         if param == '__init__.py' or param == '__pycache__': continue\n",
    "#         param = param.split('.')[0]\n",
    "#         # if os.path.isdir(os.path.join(ltr1,model,param)): continue\n",
    "#         # else:\n",
    "#         #     if not os.path.isdir(os.path.join(ltr1,model)): os.mkdir(os.path.join(ltr1,model))\n",
    "#         #     os.mkdir(os.path.join(ltr1,model,param))\n",
    "#         if os.path.isdir(os.path.join(ltr2,model,param)): continue\n",
    "#         else:\n",
    "#             if not os.path.isdir(os.path.join(ltr2,model)): os.mkdir(os.path.join(ltr2,model))\n",
    "#             os.mkdir(os.path.join(ltr2,model,param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# net_path = '/mnt/data/qizhezhang/pytracking/pytracking/networks'\n",
    "# name = ['prdimp18','prdimp50','super_dimp','super_dimp_simple']\n",
    "# for name in name:\n",
    "#     shutil.copy(os.path.join(net_path,name+'.pth.tar'),os.path.join(ltr1,'dimp',name,'DiMPnet_ep0000.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# net_path = '/mnt/data/qizhezhang/pytracking/pytracking/networks'\n",
    "# name = ['prdimp18','prdimp50','super_dimp','super_dimp_simple','dimp18','dimp50']\n",
    "# for name in name:\n",
    "#     shutil.copy(os.path.join(ltr1,'dimp',name,'DiMPnet_ep0055.pth.tar'),os.path.join(net_path,name+'.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil,os\n",
    "origin_path = '/mnt/data/qizhezhang/pytracking/pytracking/networks_old'\n",
    "net_path = '/mnt/data/qizhezhang/pytracking/pytracking/networks_tune'\n",
    "root_net = '/mnt/data/qizhezhang/pytracking/'\n",
    "a = [\n",
    "    # ('ltr/ckpt/checkpoints/ltr/kys/kys/KYSNet_ep0050.pth','kys.pth'),\n",
    "    # ('ltr/ckpt/checkpoints/ltr/lwl/lwl_boxinit/LWTLBoxNet_ep0060.pth','lwl_boxinit.pth'),\n",
    "    # ('ltr/ckpt/checkpoints/ltr/dimp/prdimp50/DiMPnet_ep0055.pth','prdimp50.pth.tar'),\n",
    "    # ('ltr/ckpt/checkpoints/ltr/dimp/dimp50/DiMPnet_ep0060.pth','dimp50.pth'),\n",
    "    # ('ltr/ckpt/checkpoints/ltr/bbreg/atom/ATOMnet_ep0050.pth','atom_default.pth'),\n",
    "    # ('ltr/ckpt/checkpoints/ltr/tomp/tomp101/ToMPnet_ep0310.pth','tomp101.pth.tar'),\n",
    "    ('ltr/ckpt/checkpoints/ltr/tamos/tamos_swin_base/TaMOsNet_ep0000.pth','tamos_swin_base.pth.tar'),\n",
    "    ('ltr/ckpt/checkpoints/ltr/tamos/tamos_resnet50/TaMOsNet_ep0000.pth','tamos_resnet50.pth.tar')\n",
    "    ]\n",
    "# for i in a:\n",
    "    # shutil.copy(os.path.join(root_net,i[0]),os.path.join(net_path,i[1]))\n",
    "for i in a:\n",
    "    shutil.copy(os.path.join(origin_path,i[1]),os.path.join(root_net,i[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
